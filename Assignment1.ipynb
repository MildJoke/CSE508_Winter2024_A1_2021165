{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing and printing transitions for file136.txt...\n",
      "Original text:\n",
      " Just Hung up one of my Strats. Quickly mounted on the wall above my piano and it seems to be quite secure. I have some heavier guitars and for them I would probably use Toggle bolts instead of the included Screws and mollies but for most of my lighter weight Fenders this is perfect.\n",
      "I just ordered a second one to go over my bar, I a glad to have found this item.\n",
      "\n",
      "After lowercase:\n",
      " just hung up one of my strats. quickly mounted on the wall above my piano and it seems to be quite secure. i have some heavier guitars and for them i would probably use toggle bolts instead of the included screws and mollies but for most of my lighter weight fenders this is perfect.\n",
      "i just ordered a second one to go over my bar, i a glad to have found this item.\n",
      "\n",
      "After tokenization:\n",
      " just hung up one of my strats . quickly mounted on the wall above my piano and it seems to be quite secure . i have some heavier guitars and for them i would probably use toggle bolts instead of the included screws and mollies but for most of my lighter weight fenders this is perfect . i just ordered a second one to go over my bar , i a glad to have found this item .\n",
      "\n",
      "After removing punctuation and blank space tokens:\n",
      " just hung up one of my strats quickly mounted on the wall above my piano and it seems to be quite secure i have some heavier guitars and for them i would probably use toggle bolts instead of the included screws and mollies but for most of my lighter weight fenders this is perfect i just ordered a second one to go over my bar i a glad to have found this item\n",
      "\n",
      "After removing stopwords:\n",
      " hung one strats quickly mounted wall piano seems quite secure heavier guitars would probably use toggle bolts instead included screws mollies lighter weight fenders perfect ordered second one go bar glad found item\n",
      "\n",
      "Processing and printing transitions for file770.txt...\n",
      "Original text:\n",
      " Arrived in 2 days with prime in safe packaging. Minor paint flaws with semi gloss finish. Plywood and plastic construction with painted plastic fretboard. Has plastic tuning keys and metal tuning gears on headstock. Paint wore away quickly on the side of fretboard at the top of the neck. The strings on the ukulele are not of quality but the ukulele can take brand name strings and tune them correctly. The bridge and nut need filing in order to effectively play chords or scales so I would consider it a novelty uke. Perfect for a toddler or young child to use instead of an expensive instrument, but will not be good to learn on or take lessons with. False spruce top and stained mahogany back and sides give it an expensive look that kids will love. Adult supervision required as there are moving parts. I bought this for my son who is turning two years old this May. See photo for comparison of an acoustic guitar (spruce top, catalpa back and sides) vs. the soprano ukulele\n",
      "\n",
      "After lowercase:\n",
      " arrived in 2 days with prime in safe packaging. minor paint flaws with semi gloss finish. plywood and plastic construction with painted plastic fretboard. has plastic tuning keys and metal tuning gears on headstock. paint wore away quickly on the side of fretboard at the top of the neck. the strings on the ukulele are not of quality but the ukulele can take brand name strings and tune them correctly. the bridge and nut need filing in order to effectively play chords or scales so i would consider it a novelty uke. perfect for a toddler or young child to use instead of an expensive instrument, but will not be good to learn on or take lessons with. false spruce top and stained mahogany back and sides give it an expensive look that kids will love. adult supervision required as there are moving parts. i bought this for my son who is turning two years old this may. see photo for comparison of an acoustic guitar (spruce top, catalpa back and sides) vs. the soprano ukulele\n",
      "\n",
      "After tokenization:\n",
      " arrived in 2 days with prime in safe packaging . minor paint flaws with semi gloss finish . plywood and plastic construction with painted plastic fretboard . has plastic tuning keys and metal tuning gears on headstock . paint wore away quickly on the side of fretboard at the top of the neck . the strings on the ukulele are not of quality but the ukulele can take brand name strings and tune them correctly . the bridge and nut need filing in order to effectively play chords or scales so i would consider it a novelty uke . perfect for a toddler or young child to use instead of an expensive instrument , but will not be good to learn on or take lessons with . false spruce top and stained mahogany back and sides give it an expensive look that kids will love . adult supervision required as there are moving parts . i bought this for my son who is turning two years old this may . see photo for comparison of an acoustic guitar ( spruce top , catalpa back and sides ) vs. the soprano ukulele\n",
      "\n",
      "After removing punctuation and blank space tokens:\n",
      " arrived in days with prime in safe packaging minor paint flaws with semi gloss finish plywood and plastic construction with painted plastic fretboard has plastic tuning keys and metal tuning gears on headstock paint wore away quickly on the side of fretboard at the top of the neck the strings on the ukulele are not of quality but the ukulele can take brand name strings and tune them correctly the bridge and nut need filing in order to effectively play chords or scales so i would consider it a novelty uke perfect for a toddler or young child to use instead of an expensive instrument but will not be good to learn on or take lessons with false spruce top and stained mahogany back and sides give it an expensive look that kids will love adult supervision required as there are moving parts i bought this for my son who is turning two years old this may see photo for comparison of an acoustic guitar spruce top catalpa back and sides the soprano ukulele\n",
      "\n",
      "After removing stopwords:\n",
      " arrived days prime safe packaging minor paint flaws semi gloss finish plywood plastic construction painted plastic fretboard plastic tuning keys metal tuning gears headstock paint wore away quickly side fretboard top neck strings ukulele quality ukulele take brand name strings tune correctly bridge nut need filing order effectively play chords scales would consider novelty uke perfect toddler young child use instead expensive instrument good learn take lessons false spruce top stained mahogany back sides give expensive look kids love adult supervision required moving parts bought son turning two years old may see photo comparison acoustic guitar spruce top catalpa back sides soprano ukulele\n",
      "\n",
      "Processing and printing transitions for file795.txt...\n",
      "Original text:\n",
      " Good\n",
      "\n",
      "After lowercase:\n",
      " good\n",
      "\n",
      "After tokenization:\n",
      " good\n",
      "\n",
      "After removing punctuation and blank space tokens:\n",
      " good\n",
      "\n",
      "After removing stopwords:\n",
      " good\n",
      "\n",
      "Processing and printing transitions for file844.txt...\n",
      "Original text:\n",
      " I've got a five person band for our Hawaiian performing arts group. These headsets make for even audio. No fading in and out as a singer moves closer or farther away from the mic, or turns her face to the right or left. They use the Shure SM58 pick-ups which are time proven. These headsets are especially good when I want to record a live performance. Anyone want to buy my stick mics and stands?\n",
      "\n",
      "After lowercase:\n",
      " i've got a five person band for our hawaiian performing arts group. these headsets make for even audio. no fading in and out as a singer moves closer or farther away from the mic, or turns her face to the right or left. they use the shure sm58 pick-ups which are time proven. these headsets are especially good when i want to record a live performance. anyone want to buy my stick mics and stands?\n",
      "\n",
      "After tokenization:\n",
      " i 've got a five person band for our hawaiian performing arts group . these headsets make for even audio . no fading in and out as a singer moves closer or farther away from the mic , or turns her face to the right or left . they use the shure sm58 pick-ups which are time proven . these headsets are especially good when i want to record a live performance . anyone want to buy my stick mics and stands ?\n",
      "\n",
      "After removing punctuation and blank space tokens:\n",
      " i got a five person band for our hawaiian performing arts group these headsets make for even audio no fading in and out as a singer moves closer or farther away from the mic or turns her face to the right or left they use the shure which are time proven these headsets are especially good when i want to record a live performance anyone want to buy my stick mics and stands\n",
      "\n",
      "After removing stopwords:\n",
      " got five person band hawaiian performing arts group headsets make even audio fading singer moves closer farther away mic turns face right left use shure time proven headsets especially good want record live performance anyone want buy stick mics stands\n",
      "\n",
      "Processing and printing transitions for file966.txt...\n",
      "Original text:\n",
      " I'm more happy with this purchase than anything I've bought recently.  It's just great.  It's simple, sturdy, well-built, and it holds my dreadnought guitar perfectly.  No room for improvement that I can find in this product.\n",
      "\n",
      "After lowercase:\n",
      " i'm more happy with this purchase than anything i've bought recently.  it's just great.  it's simple, sturdy, well-built, and it holds my dreadnought guitar perfectly.  no room for improvement that i can find in this product.\n",
      "\n",
      "After tokenization:\n",
      " i 'm more happy with this purchase than anything i 've bought recently . it 's just great . it 's simple , sturdy , well-built , and it holds my dreadnought guitar perfectly . no room for improvement that i can find in this product .\n",
      "\n",
      "After removing punctuation and blank space tokens:\n",
      " i more happy with this purchase than anything i bought recently it just great it simple sturdy and it holds my dreadnought guitar perfectly no room for improvement that i can find in this product\n",
      "\n",
      "After removing stopwords:\n",
      " happy purchase anything bought recently great simple sturdy holds dreadnought guitar perfectly room improvement find product\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text, print_steps=False):\n",
    "\n",
    "    if print_steps:\n",
    "        print(\"Original text:\\n\", text) \n",
    "    \n",
    "    text = text.lower()\n",
    "    if print_steps:\n",
    "        print(\"\\nAfter lowercase:\\n\", text)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    if print_steps:\n",
    "        print(\"\\nAfter tokenization:\\n\", ' '.join(tokens))  \n",
    "    \n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "    if print_steps:\n",
    "        print(\"\\nAfter removing punctuation and blank space tokens:\\n\", ' '.join(tokens))\n",
    "    \n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    if print_steps:\n",
    "        print(\"\\nAfter removing stopwords:\\n\", ' '.join(tokens))\n",
    "    \n",
    "    processed_text = ' '.join(tokens)\n",
    "    return processed_text\n",
    "\n",
    "folder_path = '/Users/mj/Desktop/Work/Sem6/IR/Ass1/text_files'\n",
    "new_folder_path = '/Users/mj/Desktop/Work/Sem6/IR/Ass1/newtextfiles'\n",
    "sample_files = random.sample(range(1, 1000), 5)  \n",
    "\n",
    "for i in range(1, 1000):\n",
    "    file_path = os.path.join(folder_path, f'file{i}.txt')\n",
    "    new_file_path = os.path.join(new_folder_path, f'newfile{i}.txt')\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            print_steps = i in sample_files\n",
    "            if print_steps:\n",
    "                print(f\"\\nProcessing and printing transitions for file{i}.txt...\")\n",
    "            processed_text = preprocess_text(text, print_steps=print_steps)\n",
    "        with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "            new_file.write(processed_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def create_inverted_index(folder_path):\n",
    "    inverted_index = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                for word in file.read().split():\n",
    "                    if word not in inverted_index:\n",
    "                        inverted_index[word] = [filename]\n",
    "                    elif filename not in inverted_index[word]:\n",
    "                        inverted_index[word].append(filename)\n",
    "    return inverted_index\n",
    "\n",
    "folder_path = '/Users/mj/Desktop/Work/Sem6/IR/Ass1/newtextfiles'\n",
    "inverted_index = create_inverted_index(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inverted_index.pkl', 'wb') as outfile:\n",
    "    pickle.dump(inverted_index, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inverted_index.pkl', 'rb') as infile:\n",
    "    loaded_inverted_index = pickle.load(infile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_and(doc_list1, doc_list2):\n",
    "    return list(set(doc_list1) & set(doc_list2))\n",
    "\n",
    "def query_or(doc_list1, doc_list2):\n",
    "    return list(set(doc_list1) | set(doc_list2))\n",
    "\n",
    "def query_and_not(doc_list1, doc_list2):\n",
    "    return list(set(doc_list1) - set(doc_list2))\n",
    "\n",
    "def query_or_not(doc_list1, doc_list2, all_docs):\n",
    "    return list((set(all_docs) - set(doc_list2)) | set(doc_list1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(inverted_index, query_terms, operations):\n",
    "    result = inverted_index.get(query_terms[0], [])\n",
    "    all_docs = [file for file in inverted_index.values() for file in file]\n",
    "    \n",
    "    for i, operation in enumerate(operations):\n",
    "        next_term_docs = inverted_index.get(query_terms[i + 1], [])\n",
    "        if operation == 'AND':\n",
    "            result = query_and(result, next_term_docs)\n",
    "        elif operation == 'OR':\n",
    "            result = query_or(result, next_term_docs)\n",
    "        elif operation == 'AND NOT':\n",
    "            result = query_and_not(result, next_term_docs)\n",
    "        elif operation == 'OR NOT':\n",
    "            result = query_or_not(result, next_term_docs, all_docs)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: coffee AND brewing OR NOT techniques OR cookbook\n",
      "Number of documents retrieved for query 1: 999\n",
      "Names of the documents retrieved for query 1: newfile1.txt, newfile10.txt, newfile100.txt, newfile101.txt, newfile102.txt, newfile103.txt, newfile104.txt, newfile105.txt, newfile106.txt, newfile107.txt, newfile108.txt, newfile109.txt, newfile11.txt, newfile110.txt, newfile111.txt, newfile112.txt, newfile113.txt, newfile114.txt, newfile115.txt, newfile116.txt, newfile117.txt, newfile118.txt, newfile119.txt, newfile12.txt, newfile120.txt, newfile121.txt, newfile122.txt, newfile123.txt, newfile124.txt, newfile125.txt, newfile126.txt, newfile127.txt, newfile128.txt, newfile129.txt, newfile13.txt, newfile130.txt, newfile131.txt, newfile132.txt, newfile133.txt, newfile134.txt, newfile135.txt, newfile136.txt, newfile137.txt, newfile138.txt, newfile139.txt, newfile14.txt, newfile140.txt, newfile141.txt, newfile142.txt, newfile143.txt, newfile144.txt, newfile145.txt, newfile146.txt, newfile147.txt, newfile148.txt, newfile149.txt, newfile15.txt, newfile150.txt, newfile151.txt, newfile152.txt, newfile153.txt, newfile154.txt, newfile155.txt, newfile156.txt, newfile157.txt, newfile158.txt, newfile159.txt, newfile16.txt, newfile160.txt, newfile161.txt, newfile162.txt, newfile163.txt, newfile164.txt, newfile165.txt, newfile166.txt, newfile167.txt, newfile168.txt, newfile169.txt, newfile17.txt, newfile170.txt, newfile171.txt, newfile172.txt, newfile173.txt, newfile174.txt, newfile175.txt, newfile176.txt, newfile177.txt, newfile178.txt, newfile179.txt, newfile18.txt, newfile180.txt, newfile181.txt, newfile182.txt, newfile183.txt, newfile184.txt, newfile185.txt, newfile186.txt, newfile187.txt, newfile188.txt, newfile189.txt, newfile19.txt, newfile190.txt, newfile191.txt, newfile192.txt, newfile193.txt, newfile194.txt, newfile195.txt, newfile196.txt, newfile197.txt, newfile198.txt, newfile199.txt, newfile2.txt, newfile20.txt, newfile200.txt, newfile201.txt, newfile202.txt, newfile203.txt, newfile204.txt, newfile205.txt, newfile206.txt, newfile207.txt, newfile208.txt, newfile209.txt, newfile21.txt, newfile210.txt, newfile211.txt, newfile212.txt, newfile213.txt, newfile214.txt, newfile215.txt, newfile216.txt, newfile217.txt, newfile218.txt, newfile219.txt, newfile22.txt, newfile220.txt, newfile221.txt, newfile222.txt, newfile223.txt, newfile224.txt, newfile225.txt, newfile226.txt, newfile227.txt, newfile228.txt, newfile229.txt, newfile23.txt, newfile230.txt, newfile231.txt, newfile232.txt, newfile233.txt, newfile234.txt, newfile235.txt, newfile236.txt, newfile237.txt, newfile238.txt, newfile239.txt, newfile24.txt, newfile240.txt, newfile241.txt, newfile242.txt, newfile243.txt, newfile244.txt, newfile245.txt, newfile246.txt, newfile247.txt, newfile248.txt, newfile249.txt, newfile25.txt, newfile250.txt, newfile251.txt, newfile252.txt, newfile253.txt, newfile254.txt, newfile255.txt, newfile256.txt, newfile257.txt, newfile258.txt, newfile259.txt, newfile26.txt, newfile260.txt, newfile261.txt, newfile262.txt, newfile263.txt, newfile264.txt, newfile265.txt, newfile266.txt, newfile267.txt, newfile268.txt, newfile269.txt, newfile27.txt, newfile270.txt, newfile271.txt, newfile272.txt, newfile273.txt, newfile274.txt, newfile275.txt, newfile276.txt, newfile277.txt, newfile278.txt, newfile279.txt, newfile28.txt, newfile280.txt, newfile281.txt, newfile282.txt, newfile283.txt, newfile284.txt, newfile285.txt, newfile286.txt, newfile287.txt, newfile288.txt, newfile289.txt, newfile29.txt, newfile290.txt, newfile291.txt, newfile292.txt, newfile293.txt, newfile294.txt, newfile295.txt, newfile296.txt, newfile297.txt, newfile298.txt, newfile299.txt, newfile3.txt, newfile30.txt, newfile300.txt, newfile301.txt, newfile302.txt, newfile303.txt, newfile304.txt, newfile305.txt, newfile306.txt, newfile307.txt, newfile308.txt, newfile309.txt, newfile31.txt, newfile310.txt, newfile311.txt, newfile312.txt, newfile313.txt, newfile314.txt, newfile315.txt, newfile316.txt, newfile317.txt, newfile318.txt, newfile319.txt, newfile32.txt, newfile320.txt, newfile321.txt, newfile322.txt, newfile323.txt, newfile324.txt, newfile325.txt, newfile326.txt, newfile327.txt, newfile328.txt, newfile329.txt, newfile33.txt, newfile330.txt, newfile331.txt, newfile332.txt, newfile333.txt, newfile334.txt, newfile335.txt, newfile336.txt, newfile337.txt, newfile338.txt, newfile339.txt, newfile34.txt, newfile340.txt, newfile341.txt, newfile342.txt, newfile343.txt, newfile344.txt, newfile345.txt, newfile346.txt, newfile347.txt, newfile348.txt, newfile349.txt, newfile35.txt, newfile350.txt, newfile351.txt, newfile352.txt, newfile353.txt, newfile354.txt, newfile355.txt, newfile356.txt, newfile357.txt, newfile358.txt, newfile359.txt, newfile36.txt, newfile360.txt, newfile361.txt, newfile362.txt, newfile363.txt, newfile364.txt, newfile365.txt, newfile366.txt, newfile367.txt, newfile368.txt, newfile369.txt, newfile37.txt, newfile370.txt, newfile371.txt, newfile372.txt, newfile373.txt, newfile374.txt, newfile375.txt, newfile376.txt, newfile377.txt, newfile378.txt, newfile379.txt, newfile38.txt, newfile380.txt, newfile381.txt, newfile382.txt, newfile383.txt, newfile384.txt, newfile385.txt, newfile386.txt, newfile387.txt, newfile388.txt, newfile389.txt, newfile39.txt, newfile390.txt, newfile391.txt, newfile392.txt, newfile393.txt, newfile394.txt, newfile395.txt, newfile396.txt, newfile397.txt, newfile398.txt, newfile399.txt, newfile4.txt, newfile40.txt, newfile400.txt, newfile401.txt, newfile402.txt, newfile403.txt, newfile404.txt, newfile405.txt, newfile406.txt, newfile407.txt, newfile408.txt, newfile409.txt, newfile41.txt, newfile410.txt, newfile411.txt, newfile412.txt, newfile413.txt, newfile414.txt, newfile415.txt, newfile416.txt, newfile417.txt, newfile418.txt, newfile419.txt, newfile42.txt, newfile420.txt, newfile421.txt, newfile422.txt, newfile423.txt, newfile424.txt, newfile425.txt, newfile426.txt, newfile427.txt, newfile428.txt, newfile429.txt, newfile43.txt, newfile430.txt, newfile431.txt, newfile432.txt, newfile433.txt, newfile434.txt, newfile435.txt, newfile436.txt, newfile437.txt, newfile438.txt, newfile439.txt, newfile44.txt, newfile440.txt, newfile441.txt, newfile442.txt, newfile443.txt, newfile444.txt, newfile445.txt, newfile446.txt, newfile447.txt, newfile448.txt, newfile449.txt, newfile45.txt, newfile450.txt, newfile451.txt, newfile452.txt, newfile453.txt, newfile454.txt, newfile455.txt, newfile456.txt, newfile457.txt, newfile458.txt, newfile459.txt, newfile46.txt, newfile460.txt, newfile461.txt, newfile462.txt, newfile463.txt, newfile464.txt, newfile465.txt, newfile466.txt, newfile467.txt, newfile468.txt, newfile469.txt, newfile47.txt, newfile470.txt, newfile471.txt, newfile472.txt, newfile473.txt, newfile474.txt, newfile475.txt, newfile476.txt, newfile477.txt, newfile478.txt, newfile479.txt, newfile48.txt, newfile480.txt, newfile481.txt, newfile482.txt, newfile483.txt, newfile484.txt, newfile485.txt, newfile486.txt, newfile487.txt, newfile488.txt, newfile489.txt, newfile49.txt, newfile490.txt, newfile491.txt, newfile492.txt, newfile493.txt, newfile494.txt, newfile495.txt, newfile496.txt, newfile497.txt, newfile498.txt, newfile499.txt, newfile5.txt, newfile50.txt, newfile500.txt, newfile501.txt, newfile502.txt, newfile503.txt, newfile504.txt, newfile505.txt, newfile506.txt, newfile507.txt, newfile508.txt, newfile509.txt, newfile51.txt, newfile510.txt, newfile511.txt, newfile512.txt, newfile513.txt, newfile514.txt, newfile515.txt, newfile516.txt, newfile517.txt, newfile518.txt, newfile519.txt, newfile52.txt, newfile520.txt, newfile521.txt, newfile522.txt, newfile523.txt, newfile524.txt, newfile525.txt, newfile526.txt, newfile527.txt, newfile528.txt, newfile529.txt, newfile53.txt, newfile530.txt, newfile531.txt, newfile532.txt, newfile533.txt, newfile534.txt, newfile535.txt, newfile536.txt, newfile537.txt, newfile538.txt, newfile539.txt, newfile54.txt, newfile540.txt, newfile541.txt, newfile542.txt, newfile543.txt, newfile544.txt, newfile545.txt, newfile546.txt, newfile547.txt, newfile548.txt, newfile549.txt, newfile55.txt, newfile550.txt, newfile551.txt, newfile552.txt, newfile553.txt, newfile554.txt, newfile555.txt, newfile556.txt, newfile557.txt, newfile558.txt, newfile559.txt, newfile56.txt, newfile560.txt, newfile561.txt, newfile562.txt, newfile563.txt, newfile564.txt, newfile565.txt, newfile566.txt, newfile567.txt, newfile568.txt, newfile569.txt, newfile57.txt, newfile570.txt, newfile571.txt, newfile572.txt, newfile573.txt, newfile574.txt, newfile575.txt, newfile576.txt, newfile577.txt, newfile578.txt, newfile579.txt, newfile58.txt, newfile580.txt, newfile581.txt, newfile582.txt, newfile583.txt, newfile584.txt, newfile585.txt, newfile586.txt, newfile587.txt, newfile588.txt, newfile589.txt, newfile59.txt, newfile590.txt, newfile591.txt, newfile592.txt, newfile593.txt, newfile594.txt, newfile595.txt, newfile596.txt, newfile597.txt, newfile598.txt, newfile599.txt, newfile6.txt, newfile60.txt, newfile600.txt, newfile601.txt, newfile602.txt, newfile603.txt, newfile604.txt, newfile605.txt, newfile606.txt, newfile607.txt, newfile608.txt, newfile609.txt, newfile61.txt, newfile610.txt, newfile611.txt, newfile612.txt, newfile613.txt, newfile614.txt, newfile615.txt, newfile616.txt, newfile617.txt, newfile618.txt, newfile619.txt, newfile62.txt, newfile620.txt, newfile621.txt, newfile622.txt, newfile623.txt, newfile624.txt, newfile625.txt, newfile626.txt, newfile627.txt, newfile628.txt, newfile629.txt, newfile63.txt, newfile630.txt, newfile631.txt, newfile632.txt, newfile633.txt, newfile634.txt, newfile635.txt, newfile636.txt, newfile637.txt, newfile638.txt, newfile639.txt, newfile64.txt, newfile640.txt, newfile641.txt, newfile642.txt, newfile643.txt, newfile644.txt, newfile645.txt, newfile646.txt, newfile647.txt, newfile648.txt, newfile649.txt, newfile65.txt, newfile650.txt, newfile651.txt, newfile652.txt, newfile653.txt, newfile654.txt, newfile655.txt, newfile656.txt, newfile657.txt, newfile658.txt, newfile659.txt, newfile66.txt, newfile660.txt, newfile661.txt, newfile662.txt, newfile663.txt, newfile664.txt, newfile665.txt, newfile666.txt, newfile667.txt, newfile668.txt, newfile669.txt, newfile67.txt, newfile670.txt, newfile671.txt, newfile672.txt, newfile673.txt, newfile674.txt, newfile675.txt, newfile676.txt, newfile677.txt, newfile678.txt, newfile679.txt, newfile68.txt, newfile680.txt, newfile681.txt, newfile682.txt, newfile683.txt, newfile684.txt, newfile685.txt, newfile686.txt, newfile687.txt, newfile688.txt, newfile689.txt, newfile69.txt, newfile690.txt, newfile691.txt, newfile692.txt, newfile693.txt, newfile694.txt, newfile695.txt, newfile696.txt, newfile697.txt, newfile698.txt, newfile699.txt, newfile7.txt, newfile70.txt, newfile700.txt, newfile701.txt, newfile702.txt, newfile703.txt, newfile704.txt, newfile705.txt, newfile706.txt, newfile707.txt, newfile708.txt, newfile709.txt, newfile71.txt, newfile710.txt, newfile711.txt, newfile712.txt, newfile713.txt, newfile714.txt, newfile715.txt, newfile716.txt, newfile717.txt, newfile718.txt, newfile719.txt, newfile72.txt, newfile720.txt, newfile721.txt, newfile722.txt, newfile723.txt, newfile724.txt, newfile725.txt, newfile726.txt, newfile727.txt, newfile728.txt, newfile729.txt, newfile73.txt, newfile730.txt, newfile731.txt, newfile732.txt, newfile733.txt, newfile734.txt, newfile735.txt, newfile736.txt, newfile737.txt, newfile738.txt, newfile739.txt, newfile74.txt, newfile740.txt, newfile741.txt, newfile742.txt, newfile743.txt, newfile744.txt, newfile745.txt, newfile746.txt, newfile747.txt, newfile748.txt, newfile749.txt, newfile75.txt, newfile750.txt, newfile751.txt, newfile752.txt, newfile753.txt, newfile754.txt, newfile755.txt, newfile756.txt, newfile757.txt, newfile758.txt, newfile759.txt, newfile76.txt, newfile760.txt, newfile761.txt, newfile762.txt, newfile763.txt, newfile764.txt, newfile765.txt, newfile766.txt, newfile767.txt, newfile768.txt, newfile769.txt, newfile77.txt, newfile770.txt, newfile771.txt, newfile772.txt, newfile773.txt, newfile774.txt, newfile775.txt, newfile776.txt, newfile777.txt, newfile778.txt, newfile779.txt, newfile78.txt, newfile780.txt, newfile781.txt, newfile782.txt, newfile783.txt, newfile784.txt, newfile785.txt, newfile786.txt, newfile787.txt, newfile788.txt, newfile789.txt, newfile79.txt, newfile790.txt, newfile791.txt, newfile792.txt, newfile793.txt, newfile794.txt, newfile795.txt, newfile796.txt, newfile797.txt, newfile798.txt, newfile799.txt, newfile8.txt, newfile80.txt, newfile800.txt, newfile801.txt, newfile802.txt, newfile803.txt, newfile804.txt, newfile805.txt, newfile806.txt, newfile807.txt, newfile808.txt, newfile809.txt, newfile81.txt, newfile810.txt, newfile811.txt, newfile812.txt, newfile813.txt, newfile814.txt, newfile815.txt, newfile816.txt, newfile817.txt, newfile818.txt, newfile819.txt, newfile82.txt, newfile820.txt, newfile821.txt, newfile822.txt, newfile823.txt, newfile824.txt, newfile825.txt, newfile826.txt, newfile827.txt, newfile828.txt, newfile829.txt, newfile83.txt, newfile830.txt, newfile831.txt, newfile832.txt, newfile833.txt, newfile834.txt, newfile835.txt, newfile836.txt, newfile837.txt, newfile838.txt, newfile839.txt, newfile84.txt, newfile840.txt, newfile841.txt, newfile842.txt, newfile843.txt, newfile844.txt, newfile845.txt, newfile846.txt, newfile847.txt, newfile848.txt, newfile849.txt, newfile85.txt, newfile850.txt, newfile851.txt, newfile852.txt, newfile853.txt, newfile854.txt, newfile855.txt, newfile856.txt, newfile857.txt, newfile858.txt, newfile859.txt, newfile86.txt, newfile860.txt, newfile861.txt, newfile862.txt, newfile863.txt, newfile864.txt, newfile865.txt, newfile866.txt, newfile867.txt, newfile868.txt, newfile869.txt, newfile87.txt, newfile870.txt, newfile871.txt, newfile872.txt, newfile873.txt, newfile874.txt, newfile875.txt, newfile876.txt, newfile877.txt, newfile878.txt, newfile879.txt, newfile88.txt, newfile880.txt, newfile881.txt, newfile882.txt, newfile883.txt, newfile884.txt, newfile885.txt, newfile886.txt, newfile887.txt, newfile888.txt, newfile889.txt, newfile89.txt, newfile890.txt, newfile891.txt, newfile892.txt, newfile893.txt, newfile894.txt, newfile895.txt, newfile896.txt, newfile897.txt, newfile898.txt, newfile899.txt, newfile9.txt, newfile90.txt, newfile900.txt, newfile901.txt, newfile902.txt, newfile903.txt, newfile904.txt, newfile905.txt, newfile906.txt, newfile907.txt, newfile908.txt, newfile909.txt, newfile91.txt, newfile910.txt, newfile911.txt, newfile912.txt, newfile913.txt, newfile914.txt, newfile915.txt, newfile916.txt, newfile917.txt, newfile918.txt, newfile919.txt, newfile92.txt, newfile920.txt, newfile921.txt, newfile922.txt, newfile923.txt, newfile924.txt, newfile925.txt, newfile926.txt, newfile927.txt, newfile928.txt, newfile929.txt, newfile93.txt, newfile930.txt, newfile931.txt, newfile932.txt, newfile933.txt, newfile934.txt, newfile935.txt, newfile936.txt, newfile937.txt, newfile938.txt, newfile939.txt, newfile94.txt, newfile940.txt, newfile941.txt, newfile942.txt, newfile943.txt, newfile944.txt, newfile945.txt, newfile946.txt, newfile947.txt, newfile948.txt, newfile949.txt, newfile95.txt, newfile950.txt, newfile951.txt, newfile952.txt, newfile953.txt, newfile954.txt, newfile955.txt, newfile956.txt, newfile957.txt, newfile958.txt, newfile959.txt, newfile96.txt, newfile960.txt, newfile961.txt, newfile962.txt, newfile963.txt, newfile964.txt, newfile965.txt, newfile966.txt, newfile967.txt, newfile968.txt, newfile969.txt, newfile97.txt, newfile970.txt, newfile971.txt, newfile972.txt, newfile973.txt, newfile974.txt, newfile975.txt, newfile976.txt, newfile977.txt, newfile978.txt, newfile979.txt, newfile98.txt, newfile980.txt, newfile981.txt, newfile982.txt, newfile983.txt, newfile984.txt, newfile985.txt, newfile986.txt, newfile987.txt, newfile988.txt, newfile989.txt, newfile99.txt, newfile990.txt, newfile991.txt, newfile992.txt, newfile993.txt, newfile994.txt, newfile995.txt, newfile996.txt, newfile997.txt, newfile998.txt, newfile999.txt\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('inverted_index.pkl', 'rb') as infile:\n",
    "    inverted_index = pickle.load(infile)\n",
    "\n",
    "\n",
    "def main():\n",
    "    N = int(input(\"Enter number of queries: \"))\n",
    "    for i in range(N):\n",
    "        query = input(\"Enter query: \")\n",
    "        operations = input(\"Enter operations: \").split(', ')\n",
    "        \n",
    "        preprocessed_query = preprocess_text(query)\n",
    "        query_terms = preprocessed_query.split() \n",
    "    \n",
    "        results = execute_query(inverted_index, query_terms, operations)\n",
    "        results = sorted(results)\n",
    "        \n",
    "        print(f\"Query {i+1}: {' '.join([query_terms[0]] + [op + ' ' + term for op, term in zip(operations, query_terms[1:])])}\")\n",
    "        print(f\"Number of documents retrieved for query {i+1}: {len(results)}\")\n",
    "        print(f\"Names of the documents retrieved for query {i+1}: {', '.join(results)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: 'acoustic bass'\n",
      "Number of documents retrieved: 2\n",
      "Documents containing the phrase: newfile3.txt, newfile279.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_positional_index(folder_path):\n",
    "    positional_index = defaultdict(dict)  \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                words = word_tokenize(file.read().lower())\n",
    "                words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "                for position, word in enumerate(words):\n",
    "                    if word not in positional_index:\n",
    "                        positional_index[word] = defaultdict(list)\n",
    "                    positional_index[word][filename].append(position)\n",
    "    return positional_index\n",
    "\n",
    "def save_positional_index(index, file_name='positional_index.pkl'):\n",
    "    with open(file_name, 'wb') as outfile:\n",
    "        pickle.dump(index, outfile)\n",
    "\n",
    "def load_positional_index(file_name='positional_index.pkl'):\n",
    "    with open(file_name, 'rb') as infile:\n",
    "        return pickle.load(infile)\n",
    "\n",
    "def phrase_query_search(index, query):\n",
    "    query_words = word_tokenize(query.lower())\n",
    "    if not query_words:\n",
    "        return []\n",
    "    if len(query_words) == 1:\n",
    "        return list(index.get(query_words[0], {}).keys())\n",
    "   \n",
    "    docs = set(index[query_words[0]].keys())\n",
    "    \n",
    "    for i, word in enumerate(query_words[1:], 1):\n",
    "        docs = docs.intersection({doc for doc in index[word].keys() if any(pos - i in index[query_words[0]][doc] for pos in index[word][doc])})\n",
    "    return list(docs)\n",
    "\n",
    "def main():\n",
    "    folder_path = '/Users/mj/Desktop/Work/Sem6/IR/Ass1/newtextfiles'\n",
    "    positional_index = create_positional_index(folder_path)\n",
    "    save_positional_index(positional_index)\n",
    "    loaded_index = load_positional_index()\n",
    "    \n",
    "    N = int(input(\"Enter number of phrase queries: \"))\n",
    "    for i in range(N):\n",
    "        query = input(f\"Enter phrase query {i+1}: \")\n",
    "        preprocessed_query = preprocess_text(query)\n",
    "        results = phrase_query_search(loaded_index, preprocessed_query)\n",
    "        print(f\"Query {i+1}: '{preprocessed_query}'\")\n",
    "        print(f\"Number of documents retrieved: {len(results)}\")\n",
    "        if results:\n",
    "            print(f\"Documents containing the phrase: {', '.join(results)}\")\n",
    "        else:\n",
    "            print(\"No documents contain the given phrase.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
